---
layout:     	notebook
title:     		AirBnb first booking destination prediction
author:     	Aissa EL OUAFI
tags:         Machine-Learning Supervised-Learning Kaggle Random-Forest
subtitle:    	Predict Airbnb user first booking destination
---
# AirBnb First booking destination prediction

The main goal of this competition is to predict the first booking destination. In this version I build a Random Forest Classifier to predict if a user goes to book or not


```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from matplotlib.dates import YearLocator, MonthLocator, DateFormatter
import datetime
import seaborn as sns
from scipy import stats
from scipy import integrate
from sklearn.preprocessing import OneHotEncoder
from sklearn.feature_extraction import DictVectorizer as DV
from sklearn.linear_model import LogisticRegression
from sklearn.cross_validation import train_test_split
from sklearn import metrics
from sklearn.cross_validation import cross_val_score
from sklearn.metrics import confusion_matrix
from sklearn.ensemble import ExtraTreesClassifier
plt.style.use('ggplot')
```

## Explore Data :


```python
%matplotlib inline
%pylab inline
```

    Populating the interactive namespace from numpy and matplotlib


    WARNING: pylab import has clobbered these variables: ['colors', 'indices', 'f', 'array', 'std', 'cm', 'test']
    `%matplotlib` prevents importing * from pylab and numpy



```python
train_users = pd.read_csv('train_users_2.csv')
test_users = pd.read_csv('test_users.csv')
```


```python
train_users.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>date_account_created</th>
      <th>timestamp_first_active</th>
      <th>date_first_booking</th>
      <th>gender</th>
      <th>age</th>
      <th>signup_method</th>
      <th>signup_flow</th>
      <th>language</th>
      <th>affiliate_channel</th>
      <th>affiliate_provider</th>
      <th>first_affiliate_tracked</th>
      <th>signup_app</th>
      <th>first_device_type</th>
      <th>first_browser</th>
      <th>country_destination</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>gxn3p5htnn</td>
      <td>2010-06-28</td>
      <td>20090319043255</td>
      <td>NaN</td>
      <td>-unknown-</td>
      <td>NaN</td>
      <td>facebook</td>
      <td>0</td>
      <td>en</td>
      <td>direct</td>
      <td>direct</td>
      <td>untracked</td>
      <td>Web</td>
      <td>Mac Desktop</td>
      <td>Chrome</td>
      <td>NDF</td>
    </tr>
    <tr>
      <th>1</th>
      <td>820tgsjxq7</td>
      <td>2011-05-25</td>
      <td>20090523174809</td>
      <td>NaN</td>
      <td>MALE</td>
      <td>38</td>
      <td>facebook</td>
      <td>0</td>
      <td>en</td>
      <td>seo</td>
      <td>google</td>
      <td>untracked</td>
      <td>Web</td>
      <td>Mac Desktop</td>
      <td>Chrome</td>
      <td>NDF</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4ft3gnwmtx</td>
      <td>2010-09-28</td>
      <td>20090609231247</td>
      <td>2010-08-02</td>
      <td>FEMALE</td>
      <td>56</td>
      <td>basic</td>
      <td>3</td>
      <td>en</td>
      <td>direct</td>
      <td>direct</td>
      <td>untracked</td>
      <td>Web</td>
      <td>Windows Desktop</td>
      <td>IE</td>
      <td>US</td>
    </tr>
    <tr>
      <th>3</th>
      <td>bjjt8pjhuk</td>
      <td>2011-12-05</td>
      <td>20091031060129</td>
      <td>2012-09-08</td>
      <td>FEMALE</td>
      <td>42</td>
      <td>facebook</td>
      <td>0</td>
      <td>en</td>
      <td>direct</td>
      <td>direct</td>
      <td>untracked</td>
      <td>Web</td>
      <td>Mac Desktop</td>
      <td>Firefox</td>
      <td>other</td>
    </tr>
    <tr>
      <th>4</th>
      <td>87mebub9p4</td>
      <td>2010-09-14</td>
      <td>20091208061105</td>
      <td>2010-02-18</td>
      <td>-unknown-</td>
      <td>41</td>
      <td>basic</td>
      <td>0</td>
      <td>en</td>
      <td>direct</td>
      <td>direct</td>
      <td>untracked</td>
      <td>Web</td>
      <td>Mac Desktop</td>
      <td>Chrome</td>
      <td>US</td>
    </tr>
  </tbody>
</table>
</div>




```python
countries = pd.read_csv('countries.csv')
```


```python
countries.tail()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country_destination</th>
      <th>lat_destination</th>
      <th>lng_destination</th>
      <th>distance_km</th>
      <th>destination_km2</th>
      <th>destination_language</th>
      <th>language_levenshtein_distance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5</th>
      <td>GB</td>
      <td>54.633220</td>
      <td>-3.432277</td>
      <td>6883.6590</td>
      <td>243610</td>
      <td>eng</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>6</th>
      <td>IT</td>
      <td>41.873990</td>
      <td>12.564167</td>
      <td>8636.6310</td>
      <td>301340</td>
      <td>ita</td>
      <td>89.40</td>
    </tr>
    <tr>
      <th>7</th>
      <td>NL</td>
      <td>52.133057</td>
      <td>5.295250</td>
      <td>7524.3203</td>
      <td>41543</td>
      <td>nld</td>
      <td>63.22</td>
    </tr>
    <tr>
      <th>8</th>
      <td>PT</td>
      <td>39.553444</td>
      <td>-7.839319</td>
      <td>7355.2534</td>
      <td>92090</td>
      <td>por</td>
      <td>95.45</td>
    </tr>
    <tr>
      <th>9</th>
      <td>US</td>
      <td>36.966427</td>
      <td>-95.844030</td>
      <td>0.0000</td>
      <td>9826675</td>
      <td>eng</td>
      <td>0.00</td>
    </tr>
  </tbody>
</table>
</div>




```python
test_users = pd.read_csv('test_users.csv')
```


```python
train_users.info()
```

    <class 'pandas.core.frame.DataFrame'>
    Int64Index: 213451 entries, 0 to 213450
    Data columns (total 16 columns):
    id                         213451 non-null object
    date_account_created       213451 non-null object
    timestamp_first_active     213451 non-null int64
    date_first_booking         88908 non-null object
    gender                     213451 non-null object
    age                        125461 non-null float64
    signup_method              213451 non-null object
    signup_flow                213451 non-null int64
    language                   213451 non-null object
    affiliate_channel          213451 non-null object
    affiliate_provider         213451 non-null object
    first_affiliate_tracked    207386 non-null object
    signup_app                 213451 non-null object
    first_device_type          213451 non-null object
    first_browser              213451 non-null object
    country_destination        213451 non-null object
    dtypes: float64(1), int64(2), object(13)
    memory usage: 27.7+ MB



```python
print("We have :",train_users.shape[0],"users in train data with ",train_users.shape[1]," variables and ",test_users.shape[0]," in the test data")
```

    ('We have :', 213451, 'users in train data with ', 16, ' variables and ', 62096, ' in the test data')



```python
print("# users ",train_users.shape[0]+train_users.shape[1])
```

    ('# users ', 213467)



```python
test_users.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>date_account_created</th>
      <th>timestamp_first_active</th>
      <th>date_first_booking</th>
      <th>gender</th>
      <th>age</th>
      <th>signup_method</th>
      <th>signup_flow</th>
      <th>language</th>
      <th>affiliate_channel</th>
      <th>affiliate_provider</th>
      <th>first_affiliate_tracked</th>
      <th>signup_app</th>
      <th>first_device_type</th>
      <th>first_browser</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5uwns89zht</td>
      <td>2014-07-01</td>
      <td>20140701000006</td>
      <td>NaN</td>
      <td>FEMALE</td>
      <td>35</td>
      <td>facebook</td>
      <td>0</td>
      <td>en</td>
      <td>direct</td>
      <td>direct</td>
      <td>untracked</td>
      <td>Moweb</td>
      <td>iPhone</td>
      <td>Mobile Safari</td>
    </tr>
    <tr>
      <th>1</th>
      <td>jtl0dijy2j</td>
      <td>2014-07-01</td>
      <td>20140701000051</td>
      <td>NaN</td>
      <td>-unknown-</td>
      <td>NaN</td>
      <td>basic</td>
      <td>0</td>
      <td>en</td>
      <td>direct</td>
      <td>direct</td>
      <td>untracked</td>
      <td>Moweb</td>
      <td>iPhone</td>
      <td>Mobile Safari</td>
    </tr>
    <tr>
      <th>2</th>
      <td>xx0ulgorjt</td>
      <td>2014-07-01</td>
      <td>20140701000148</td>
      <td>NaN</td>
      <td>-unknown-</td>
      <td>NaN</td>
      <td>basic</td>
      <td>0</td>
      <td>en</td>
      <td>direct</td>
      <td>direct</td>
      <td>linked</td>
      <td>Web</td>
      <td>Windows Desktop</td>
      <td>Chrome</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6c6puo6ix0</td>
      <td>2014-07-01</td>
      <td>20140701000215</td>
      <td>NaN</td>
      <td>-unknown-</td>
      <td>NaN</td>
      <td>basic</td>
      <td>0</td>
      <td>en</td>
      <td>direct</td>
      <td>direct</td>
      <td>linked</td>
      <td>Web</td>
      <td>Windows Desktop</td>
      <td>IE</td>
    </tr>
    <tr>
      <th>4</th>
      <td>czqhjk3yfe</td>
      <td>2014-07-01</td>
      <td>20140701000305</td>
      <td>NaN</td>
      <td>-unknown-</td>
      <td>NaN</td>
      <td>basic</td>
      <td>0</td>
      <td>en</td>
      <td>direct</td>
      <td>direct</td>
      <td>untracked</td>
      <td>Web</td>
      <td>Mac Desktop</td>
      <td>Safari</td>
    </tr>
  </tbody>
</table>
</div>




```python
sessions = pd.read_csv('sessions.csv')
```


```python
sessions.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>action</th>
      <th>action_type</th>
      <th>action_detail</th>
      <th>device_type</th>
      <th>secs_elapsed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>d1mm9tcy42</td>
      <td>lookup</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Windows Desktop</td>
      <td>319</td>
    </tr>
    <tr>
      <th>1</th>
      <td>d1mm9tcy42</td>
      <td>search_results</td>
      <td>click</td>
      <td>view_search_results</td>
      <td>Windows Desktop</td>
      <td>67753</td>
    </tr>
    <tr>
      <th>2</th>
      <td>d1mm9tcy42</td>
      <td>lookup</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Windows Desktop</td>
      <td>301</td>
    </tr>
    <tr>
      <th>3</th>
      <td>d1mm9tcy42</td>
      <td>search_results</td>
      <td>click</td>
      <td>view_search_results</td>
      <td>Windows Desktop</td>
      <td>22141</td>
    </tr>
    <tr>
      <th>4</th>
      <td>d1mm9tcy42</td>
      <td>lookup</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>Windows Desktop</td>
      <td>435</td>
    </tr>
  </tbody>
</table>
</div>




```python
sessions.describe()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>secs_elapsed</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>10431706.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>19405.810751</td>
    </tr>
    <tr>
      <th>std</th>
      <td>88884.243209</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>229.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1147.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>8444.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1799977.000000</td>
    </tr>
  </tbody>
</table>
</div>



## Missing Data
We should detect the missing data and replace them with `Nan`, if we see the `gender` colomun of `train_users`, we can show that we have a lot of `-unkonown-` value in the gender column :


```python
train_users.gender.replace('-unknown-',np.nan, inplace=True)
```

Lets show the number of missing gender for example


```python
print("The number of missing gender user is ", train_users.gender.isnull().sum())
print("The number of missing age in train_user is : ",train_users.age.isnull().sum())
print("The total number of train_user is : ",train_users.shape[0])
```

    ('The number of missing gender user is ', 95688)
    ('The number of missing age in train_user is : ', 87990)
    ('The total number of train_user is : ', 213451)



```python
users_nan = (train_users.isnull().sum()/train_users.shape[0])*100
users_nan[users_nan > 0].head()
```




    date_first_booking         58.347349
    gender                     44.829024
    age                        41.222576
    first_affiliate_tracked     2.841402
    dtype: float64




```python
print("The number of minor users is : ",sum(train_users.age < 18))
```

    ('The number of minor users is : ', 158)



```python
print("The number of users superior than 120 years is ",sum(train_users.age > 122))
```

    ('The number of users superior than 120 years is ', 781)


So, we have 158 dosn't respect the politic of Airbnb and 781 with more than 122 years


```python
train_users[train_users.age > 122].describe()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>timestamp_first_active</th>
      <th>age</th>
      <th>signup_flow</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>7.810000e+02</td>
      <td>781.000000</td>
      <td>781.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2.012670e+13</td>
      <td>2006.308579</td>
      <td>1.610755</td>
    </tr>
    <tr>
      <th>std</th>
      <td>9.289315e+09</td>
      <td>95.711349</td>
      <td>5.175840</td>
    </tr>
    <tr>
      <th>min</th>
      <td>2.010041e+13</td>
      <td>132.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>2.012061e+13</td>
      <td>2014.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>2.013032e+13</td>
      <td>2014.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>2.013093e+13</td>
      <td>2014.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2.014063e+13</td>
      <td>2014.000000</td>
      <td>25.000000</td>
    </tr>
  </tbody>
</table>
</div>




```python
train_users[train_users.age < 18].describe()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>timestamp_first_active</th>
      <th>age</th>
      <th>signup_flow</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1.580000e+02</td>
      <td>158.000000</td>
      <td>158.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2.012341e+13</td>
      <td>12.202532</td>
      <td>2.917722</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.660633e+10</td>
      <td>5.916359</td>
      <td>5.799149</td>
    </tr>
    <tr>
      <th>min</th>
      <td>2.010031e+13</td>
      <td>1.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>2.010091e+13</td>
      <td>5.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>2.013062e+13</td>
      <td>16.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>2.014021e+13</td>
      <td>17.000000</td>
      <td>2.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2.014063e+13</td>
      <td>17.000000</td>
      <td>25.000000</td>
    </tr>
  </tbody>
</table>
</div>



## Visualizing data
We Will try to present our data depending to different kind of features


```python
train_users.gender.value_counts(dropna=False).plot(kind='bar',color='#FD5C64',rot = 0,figsize=(24,10),fontsize=20)
plt.xlabel("Gender")
sns.despine()
```


![png](output_28_0.png)


Note that most users (~100 000 users) do not specify their gender.


```python
destination_percentage = train_users.country_destination.value_counts() / train_users.shape[0]*100
destination_percentage.plot(kind='bar',color='#226666',rot=0,figsize=(24,10),fontsize=20)
plt.xlabel("Country destination")
plt.ylabel("User percentage")
sns.despine()
```


![png](output_30_0.png)



```python
train_users_except_ndf = train_users[train_users.country_destination != "NDF"]
destination_percentage = train_users_except_ndf.country_destination.value_counts() / train_users_except_ndf.shape[0]*100
destination_percentage.plot(kind='bar',figsize=(22,10),fontsize=20)
plt.xlabel("Country destination - except NDF -")
plt.ylabel("User percentage")
sns.despine()
```


![png](output_31_0.png)


As we can see all 12 classes are represented in the training data and we can see that nearly <b> 60% of users do not make a booking </b>. Of the users that book, about <b>70 % do so in the US</b>.

## Languages


```python
user_languages = train_users.language.value_counts() / train_users.shape[0] * 100
user_languages.plot(kind='bar',color='#689999',rot=0,figsize=(24,10),fontsize=20)
plt.title("Languages including English ")
figure
```




    <function matplotlib.pyplot.figure>




![png](output_33_1.png)


As we can see 98% of users speak English, this figure isn't verry useful, so let's see the histogram of languages without English.


```python
user_languages = train_users[train_users.language != "en"].language.value_counts() / train_users.shape[0] * 100
user_languages.plot(kind='bar',rot=0,figsize=(24,10),fontsize=20)
plt.title("Language except English")
```




    <matplotlib.text.Text at 0x118603a10>




![png](output_35_1.png)


## Gender :


```python
women = sum(train_users.gender == 'FEMALE')
men = sum(train_users.gender == 'MALE')

female_destination = train_users.loc[train_users.gender == 'FEMALE', 'country_destination'].value_counts() / women *100
men_destination = train_users.loc[train_users.gender == 'MALE','country_destination'].value_counts() / men * 100

width = 0.4

female_destination.plot(kind = 'bar', width=width, rot=0, color='#ffdcad', label='Women', position=0,figsize=(24,10))
men_destination.plot(kind='bar',width=width,rot=0,color='#7f5215',label='Men',position=1,figsize=(24,10),fontsize=20)

plt.xlabel("Destination country")
plt.ylabel("Percentage")
plt.legend()
plt.show()
```


![png](output_37_0.png)


We can say that there is <b>no difference</b> between the two gender, so this figure isn't verry useful !

## Age
Lets see now the influence of the age :


```python
train_users_age  = train_users[np.isfinite(train_users['age'])]
countries = train_users_age.country_destination.unique()
data_to_plot = []

## create the dataplot from the train users dataframe
for country in countries:
    data_to_plot.append(train_users_age[train_users_age.country_destination == country].age)

## create a figure instance
fig = plt.figure(1,figsize(24,10))
# Create an axes instance
ax = fig.add_subplot(111)


# Create the boxplot
bp = ax.boxplot(data_to_plot,vert=True,patch_artist=True)

## Custom x-axis labels
ax.set_xticklabels(train_users_age.country_destination.unique())


plt.xlabel("countries")
plt.ylabel("age")
plt.ylim([25,50])
plt.show()
```


![png](output_40_0.png)


The age show some interesting differentiation by country destination that could be useful. Users how book trips to <b> Spain </b> and <b> Portugal </b> tend to be younger while those that book trips to <b>Great Britain</b> or <b> United States</b>.


```python
sns.distplot(train_users.age.dropna(),hist=False,color="g")
plt.xlabel('Age')
plt.xlim([0,140])
sns.despine()
```


![png](output_42_0.png)


We can say that the majority of people book between 30 and 50 years, Lets now plot the <b> age by destination density </b> for differents countries that we have, Use the <b>KDE (Kernel Density Estimator)</b> using <b> Gaussian Kernel</b> in order to estimate the probability density function of age variable in non parametric way, the goal is to plot the density of people how book depending of out age, We can evalue the quality of this estimator :


```python
age_country_users = pd.concat([train_users['age'],train_users['country_destination']],axis=1,keys=['age','country_destination'])
age_country_users = age_country_users[np.isfinite(age_country_users['age'])]
```


```python
sns.kdeplot(age_country_users[age_country_users.country_destination == "US"].age,label="US")
sns.kdeplot(age_country_users[age_country_users.country_destination == "NDF"].age,label="NDF")
sns.kdeplot(age_country_users[age_country_users.country_destination == "other"].age,label="other")
sns.kdeplot(age_country_users[age_country_users.country_destination == "FR"].age,label="FR")
plt.xlim([0,100])
plt.legend()
```




    <matplotlib.legend.Legend at 0x11877f6d0>




![png](output_45_1.png)



```python
kde = stats.gaussian_kde(age_country_users[age_country_users.country_destination == "US"].age)
array = kde.evaluate(age_country_users[age_country_users.country_destination == "US"].age)
```


```python
print "The quality of the Kernel Density Estimator using the Gaussian Kernel for US destination is : ",(1-np.median(array))*100, "% It's PERFECT !"
```

    The quality of the Kernel Density Estimator using the Gaussian Kernel for US destination is :  98.0878646945 % It's PERFECT !


# Date visualization :
## First booking date visualization :


```python
book_user = train_users.dropna(subset=['date_first_booking']) #Delete NaN value from date_first_booking column
df =  book_user.groupby(['date_first_booking']).size().reset_index()
ts = pd.Series(df[0].values, index=pd.date_range(start='2/1/2010', end='30/6/2015'))
ax  = ts.plot(title="Airbnb users booking",colormap='BrBG',figsize=(24,10),fontsize=20)
#ax.set_xlim(pd.Timestamp('2015-01-01'), pd.Timestamp('2015-6-30'))
ax.set_ylim(0,260)
#df.describe()
```




    (0, 260)




![png](output_49_1.png)


Note the number of reservations down during Christmas holidays and increase in sumer.

## Signup date visualization :
We will try to show the number of signup by day :


```python
df =  train_users.groupby(['date_account_created']).size().reset_index()
ts = pd.Series(df[0].values, index=pd.date_range('1/1/2010', periods=1634))
ax  = ts.plot(title="Airbnb users signup",colormap='RdBu_r',figsize=(24,10),fontsize=20)
```


![png](output_52_0.png)


## Signup method visualizing :


```python
signup_percentage = train_users.signup_method.value_counts()/train_users.shape[0]*100;
colors = ['#AFCCCC', '#71525C', '#AAA95A']
signup_percentage.plot(kind='pie',figsize=(6,6),rot = 0,colors=colors)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x112fd8c50>




![png](output_54_1.png)


## Sessions :


```python
users_secs_elpased = sessions.groupby('user_id')['secs_elapsed'].sum().reset_index()
train = pd.concat([train_users.set_index('id'), sessions.groupby('user_id')['secs_elapsed'].sum()/3600], axis=1).reset_index()
train.boxplot(column='secs_elapsed',by='country_destination',figsize=(24,10),fontsize=20)
plt.ylim([0,1000])
```




    (0, 1000)




![png](output_56_1.png)


We put the total of `secs elapsed` into a `df` from each user, the main goal of this approach is to plot the total of <b>secs elapsed depending if user book or not</b>, this approach can help us to define if its important to take care of time elapsed or not. We see that people how didn't book spen <b>less time</b> than those how book. We see also that people how book to Italy spend a lot of time compared to the other country destination.


```python
train = train[np.isfinite(train['secs_elapsed'])]
sns.kdeplot(train[train.country_destination == "US"].secs_elapsed,label="US")
sns.kdeplot(train[train.country_destination == "NDF"].secs_elapsed,label="NDF")
sns.kdeplot(train[train.country_destination == "FR"].secs_elapsed,label="FR")
sns.kdeplot(train[train.country_destination == "GB"].secs_elapsed,label="GB")
sns.kdeplot(train[train.country_destination == "IT"].secs_elapsed,label="IT")
sns.kdeplot(train[train.country_destination == "ES"].secs_elapsed,label="ES")
plt.xlim([0,2500])
```




    (0, 2500)




![png](output_58_1.png)



```python
sessions.head()
#sessions.action.unique()
users_action = sessions.groupby('user_id')['action'].count().reset_index()
train_action = pd.concat([train.set_index('index'), sessions.groupby('user_id')['action'].count()], axis=1).reset_index()
train_action.boxplot(column='action',by='country_destination',figsize=(24,10),fontsize=20)
plt.ylim([0,150])
```




    (0, 150)




![png](output_59_1.png)


As we can say, <b>people how doesn't book do much less action</b> compared to people how book. In average people how doesn't book do 10 actions and people how book do 14 actions in average.


```python
sessions['Count']=1
unique_count_action = sessions.pivot_table('Count', index='user_id',columns='action', aggfunc='sum', fill_value=0)
train_action_count = pd.concat([train_action.set_index('index'), unique_count_action], axis=1).reset_index()
train_action_count = train_action_count[pd.notnull(train_action_count['date_account_created'])]
train_action_count = train_action_count[pd.notnull(train_action_count['about_us'])]
#train_action_count.info()
train_action_count.info()
```

    <class 'pandas.core.frame.DataFrame'>
    Int64Index: 72543 entries, 0 to 135482
    Columns: 377 entries, level_0 to zendesk_login_jwt
    dtypes: float64(363), int64(1), object(13)
    memory usage: 209.2+ MB


## Linear correlation matrix :
The purpose is to show the features correlation and establish relations beetween features.


```python
#df_action_count = encode_onehot(train_action_count,categorical_columns)
#df_action_count = df_action_count.drop('level_0',axis=1)
#df_action_count = df_action_count.drop('timestamp_first_active',axis=1)
#df_action_count = df_action_count.drop('date_first_booking',axis=1)
#df_action_count = df_action_count.drop('gender',axis=1)
#df_action_count = df_action_count.drop('date_account_created',axis=1)
#df_action_count = df_action_count.drop('first_affiliate_tracked',axis=1)
#df_action_count.age.fillna(0,inplace = True)
#df_action_count.loc[df_action_count['country_destination'] =='NDF', 'country_destination'] = 0
#df_action_count.loc[df_action_count['country_destination'] !=0, 'country_destination'] = 1
```


```python
'''
df_action_count.info()

# Separe train and test data :
msk = np.random.rand(len(df_action_count)) < 0.8
train = df_action_count[msk]
test = df_action_count[~msk]

# Define the random forest classifier model :
rf = RandomForestClassifier(n_estimators=100)


# The array of target label in order to fit the model
train_target = train.country_destination.values.astype(int)
test_target = test.country_destination.values.astype(int)

# Drop the target field from data and train set
train = train.drop('country_destination',1)
test = test.drop('country_destination',1)

# Fit the logistic regression model on train data
rf.fit(train, train_target)


# Evaluate the regression logistic model
preds = rf.predict(test)
print "The final train set : ",len(train)," and the final test set : ",len(test)
print "The score of the random forest classifier is : ",100-metrics.mean_absolute_error(test_target, preds)*100," %" #evaluate performance
pd.set_option('display.max_columns', None)
'''
```




    '\ndf_action_count.info()\n\n# Separe train and test data : \nmsk = np.random.rand(len(df_action_count)) < 0.8\ntrain = df_action_count[msk]\ntest = df_action_count[~msk]\n\n# Define the random forest classifier model : \nrf = RandomForestClassifier(n_estimators=100)\n\n\n# The array of target label in order to fit the model\ntrain_target = train.country_destination.values.astype(int)\ntest_target = test.country_destination.values.astype(int)\n\n# Drop the target field from data and train set\ntrain = train.drop(\'country_destination\',1)\ntest = test.drop(\'country_destination\',1)\n\n# Fit the logistic regression model on train data\nrf.fit(train, train_target)\n\n\n# Evaluate the regression logistic model \npreds = rf.predict(test)\nprint "The final train set : ",len(train)," and the final test set : ",len(test)\nprint "The score of the random forest classifier is : ",100-metrics.mean_absolute_error(test_target, preds)*100," %" #evaluate performance\npd.set_option(\'display.max_columns\', None)\n'




```python
sns.set(style="white")
sns.set(font_scale=1.2)

# Compute the correlation matrix
corr = train_action.corr()

# Generate a mask for the upper triangle
mask = np.zeros_like(corr, dtype=np.bool)
mask[np.triu_indices_from(mask)] = True

# Set up the matplotlib figure
f, ax = plt.subplots(figsize=(11, 9))
plt.title("Linear matrix correlation between features")
sns.heatmap(corr)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x113678690>




![png](output_65_1.png)


## Feature engineering :  Preprocessing step and encoding categorical features using OneHotEncoder

The main goal of this approach is to encode categorical features (gender, language ...) using the OneHotEncoder algorithm


```python
categorical_columns = ['gender','signup_method','language','affiliate_channel','affiliate_provider','first_affiliate_tracked','signup_app','first_device_type','first_browser']
```


```python
def encode_onehot(df, cols):
    vec = DV()
    vec_data = pd.DataFrame(vec.fit_transform(df[cols].to_dict(outtype='records')).toarray())
    vec_data.columns = vec.get_feature_names()
    vec_data.index = df.index
    df = df.drop(cols, axis=1)
    df = df.join(vec_data)
    return df
```


```python
explore_session_data = pd.concat([train_action.set_index('index'), unique_count_action], axis=1).reset_index()
df = encode_onehot(explore_session_data,categorical_columns)
df = df.drop(['timestamp_first_active','level_0','date_first_booking','gender','date_account_created','signup_method','language','affiliate_channel','affiliate_provider','first_affiliate_tracked','signup_app','first_device_type','first_browser'],1)
df.loc[df['country_destination'] =='NDF', 'country_destination'] = 0
df.loc[df['country_destination'] !=0, 'country_destination'] = 1
```

    /usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:3: FutureWarning: the 'outtype' keyword is deprecated, use 'orient' instead
      app.launch_new_instance()


## Random forest classifier :

The goal of this approach is to define if a user <b>will book or not</b>, if the algorithm predict that user will book, we will try to determine <b>the country destination</b>.


```python
# Replace missing signup flow missing data with 0
df.signup_flow.fillna(0, inplace=True)

# Replace missing age with 0
df.age.fillna(0, inplace=True)

# Replace missing secs_elapsed with 0
df.secs_elapsed.fillna(0, inplace=True)

df.fillna(0, inplace = True)
```


```python
# Separe train and test data :
msk = np.random.rand(len(df)) < 0.8
train = df[msk]
test = df[~msk]

# Define the random forest classifier model :
rf = RandomForestClassifier()

# The array of target label in order to fit the model
train_target = train.country_destination.values.astype(int)
test_target = test.country_destination.values.astype(int)

# Drop the target field from data and train set
train = train.drop('country_destination',1)
test = test.drop('country_destination',1)

# Fit the random forest classifier model on train data
rf.fit(train, train_target)

# Evaluate the regression logistic model
preds = rf.predict(test)
print "The final train set : ",len(train)," and the final test set : ",len(test)
print "The score of the random forest classifier is : ",100-metrics.mean_absolute_error(test_target, preds)*100," %" #evaluate performance
pd.set_option('display.max_columns', None)
```

    The final train set :  108326  and the final test set :  27157
    The score of the random forest classifier is :  85.7532127996  %


### Let's see the confusion matrix of this model :


```python
cm = confusion_matrix(test_target,preds)
sns.heatmap(cm,annot=True,fmt='.6g')
plt.title("Confusion matrix of the random forest classifier")
plt.xlabel("Predicted")
plt.ylabel("Target")
```




    <matplotlib.text.Text at 0x12ad58ed0>




![png](output_74_1.png)



```python
false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(test_target, preds)
roc_auc = metrics.auc(false_positive_rate, true_positive_rate)
plt.title('ROC curve for the random forest classifier')
plt.plot(false_positive_rate, true_positive_rate,label='AUC = %0.2f'% roc_auc)
plt.legend(loc='lower right')
plt.plot([0,1],[0,1],'r--')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()
```


![png](output_75_0.png)



```python
# Build a forest and compute the feature importances
forest = ExtraTreesClassifier(n_estimators=250,random_state=0)
forest.fit(train, train_target)
importances = forest.feature_importances_
std = np.std([tree.feature_importances_ for tree in forest.estimators_],axis=0)
indices = np.argsort(importances)[::-1]
list = train.columns.values
# Print the feature ranking
#print("Feature ranking:")

#for f in range(train.shape[1]):
#    print("%d. feature %d (%f)" % (f + 1, indices[f], importances[indices[f]]))

# Plot the feature importances of the forest
plt.figure(figsize=(20, 10))
plt.title("Feature importances")
plt.bar(range(train.shape[1]), importances[indices],color='#ffdcad', yerr=std[indices], align="center")
plt.xticks(range(train.shape[1]), indices)
plt.xlim([-1, 21])
plt.ylim([0,.25])
plt.xlabel("Feature importance")
plt.ylabel("Feature label")
plt.show()
```


![png](output_76_0.png)


As we can see the most important feature is the `secs_elapsed` and the number of action based to `sessions` data.
